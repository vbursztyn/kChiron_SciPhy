{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Features:\n",
    "\n",
    "* Datetime to index all operations;\n",
    "* Optionally saves all raw data files.\n",
    "* Logs raw data files, remote APIs, API calls, data ETL, persistence of preliminary data files, and workflow executions.\n",
    "\n",
    "Output: pickle file in '[current_path]/trial/trial-[k].padp'\n",
    "\n",
    "Operations:\n",
    "\n",
    "* load_dataset(file_path, label=None)\n",
    "* register_url(base_url, label=None)\n",
    "* query_url(query_path, query_phrase, label=None)\n",
    "* modify_data(columns, row_ids, label=None)\n",
    "* interaction_by_scientist(column, value, label=None)\n",
    "* save(partial_result, label=None)\n",
    "* run_workflow(workflow_name, run_environment, configurations, label=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "import os\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class jupyterPADP():\n",
    "    \n",
    "    save_raw = False\n",
    "\n",
    "    DATASETS = {}\n",
    "    URLS = {}\n",
    "    QUERIES = {}\n",
    "    ETLS = {}\n",
    "    INTERACTIONS = {}\n",
    "    RESULTS = {}\n",
    "    RUNS = {}\n",
    "    \n",
    "    t_id = 0\n",
    "    path = None\n",
    "    \n",
    "    def __init__(self, save_raw=False):\n",
    "        self.save_raw = save_raw\n",
    "        self.path = os.path.join(os.getcwd(), 'trials')\n",
    "        self.t_id = 0\n",
    "        \n",
    "        if not os.path.exists(self.path):\n",
    "            os.makedirs(self.path)\n",
    "        else:\n",
    "            onlyfiles = next(os.walk(self.path))[2]\n",
    "            self.t_id = len(onlyfiles)\n",
    "    \n",
    "    def get_now(self):\n",
    "        return datetime.datetime.now()\n",
    "    \n",
    "    def load_dataset(self, file_path, label=None):\n",
    "        dataset_obj = {}\n",
    "        dataset_obj['path'] = file_path\n",
    "        \n",
    "        if self.save_raw:\n",
    "            try:\n",
    "                with open(file_path, 'r') as f:\n",
    "                    dataset_obj['content'] = f.read()\n",
    "            except:\n",
    "                pass\n",
    "        \n",
    "        if label:\n",
    "            dataset_obj['label'] = label  \n",
    "        self.DATASETS[self.get_now()] = dataset_obj\n",
    "    \n",
    "    def register_url(self, base_url, label=None):\n",
    "        urls_obj = {}\n",
    "        urls_obj['base_url'] = base_url\n",
    "        if label:\n",
    "            urls_obj['label'] = label  \n",
    "        self.URLS[self.get_now()] = urls_obj\n",
    "    \n",
    "    def query_url(self, query_path, query_phrase, label=None):\n",
    "        query_obj = {}\n",
    "        query_obj['query_path'] = query_path\n",
    "        query_obj['query_phrase'] = query_phrase\n",
    "        if label:\n",
    "            query_obj['label'] = label  \n",
    "        self.QUERIES[self.get_now()] = query_obj\n",
    "    \n",
    "    def modify_data(self, columns, row_ids, label=None):\n",
    "        etl_obj = {}\n",
    "        etl_obj['columns'] = columns\n",
    "        etl_obj['row_ids'] = row_ids\n",
    "        if label:\n",
    "            etl_obj['label'] = label  \n",
    "        self.ETLS[self.get_now()] = etl_obj\n",
    "    \n",
    "    def interaction_by_scientist(self, column, value, label=None):\n",
    "        interaction_obj = {}\n",
    "        interaction_obj['column'] = column\n",
    "        interaction_obj['value'] = value\n",
    "        if label:\n",
    "            interaction_obj['label'] = label  \n",
    "        self.INTERACTIONS[self.get_now()] = interaction_obj\n",
    "        \n",
    "    def run_workflow(self, workflow_name, run_environment, configurations, label=None):\n",
    "        run_obj = {}\n",
    "        run_obj['workflow_name'] = workflow_name\n",
    "        run_obj['run_environment'] = run_environment\n",
    "        run_obj['configurations'] = configurations\n",
    "        if label:\n",
    "            run_obj['label'] = label  \n",
    "        self.RUNS[self.get_now()] = run_obj\n",
    "    \n",
    "    def save(self, partial_result, label=None):\n",
    "        save_obj = {}\n",
    "        save_obj['content'] = partial_result\n",
    "        if label:\n",
    "            save_obj['label'] = label  \n",
    "        self.RESULTS[self.get_now()] = save_obj\n",
    "    \n",
    "    def commit(self):\n",
    "        dump_obj = {}\n",
    "        dump_obj['DATASETS'] = self.DATASETS\n",
    "        dump_obj['URLS'] = self.URLS\n",
    "        dump_obj['QUERIES'] = self.QUERIES\n",
    "        dump_obj['ETLS'] = self.ETLS\n",
    "        dump_obj['INTERACTIONS'] = self.INTERACTIONS\n",
    "        dump_obj['RESULTS'] = self.RESULTS\n",
    "        dump_obj['RUNS'] = self.RUNS\n",
    "        \n",
    "        with open(os.path.join(self.path, 'trial-%s.padp'%self.t_id), 'wb') as f:\n",
    "            pickle.dump(dump_obj, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
